{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "dragan-keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwZckpzYY5x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow' # 也可以使用 tensorflow\n",
        "#os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,exception_verbosity=high'\n",
        "os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_compile'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjC5lbRqY5x_",
        "colab_type": "text"
      },
      "source": [
        "modifed from https://github.com/martinarjovsky/WassersteinGAN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JBgz3JzY5yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
        "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import relu\n",
        "from keras.initializers import RandomNormal\n",
        "conv_init = RandomNormal(0, 0.02)\n",
        "gamma_init = RandomNormal(1., 0.02)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6-9m626Y5yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DCGAN_D(isize, nz, nc, ndf, n_extra_layers=0):\n",
        "    assert isize%2==0\n",
        "    _ = inputs = Input(shape=(nc, isize, isize))\n",
        "    _ = Conv2D(filters=ndf, kernel_size=4, strides=2, use_bias=False,\n",
        "                        padding = \"same\",\n",
        "                        kernel_initializer = conv_init, \n",
        "                        name = 'initial.conv.{0}-{1}'.format(nc, ndf)             \n",
        "                        ) (_)\n",
        "    _ = LeakyReLU(alpha=0.2, name = 'initial.relu.{0}'.format(ndf))(_)\n",
        "    csize, cndf = isize// 2, ndf\n",
        "    while csize > 5:\n",
        "        assert csize%2==0\n",
        "        in_feat = cndf\n",
        "        out_feat = cndf*2\n",
        "        _ = Conv2D(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
        "                        padding = \"same\",\n",
        "                        kernel_initializer = conv_init,\n",
        "                        name = 'pyramid.{0}-{1}.conv'.format(in_feat, out_feat)             \n",
        "                        ) (_)\n",
        "        if 0: # toggle batchnormalization\n",
        "            _ = BatchNormalization(name = 'pyramid.{0}.batchnorm'.format(out_feat),                                   \n",
        "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
        "                                   gamma_initializer = gamma_init, \n",
        "                                  )(_, training=1)        \n",
        "        _ = LeakyReLU(alpha=0.2, name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
        "        csize, cndf = (csize+1)//2, cndf*2\n",
        "    _ = Conv2D(filters=1, kernel_size=csize, strides=1, use_bias=False,\n",
        "                        kernel_initializer = conv_init,\n",
        "                        name = 'final.{0}-{1}.conv'.format(cndf, 1)         \n",
        "                        ) (_)\n",
        "    outputs = Flatten()(_)\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0862KAxY5yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DCGAN_G(isize, nz, nc, ngf, n_extra_layers=0):\n",
        "    cngf= ngf//2\n",
        "    tisize = isize\n",
        "    while tisize > 5:\n",
        "        cngf = cngf * 2\n",
        "        assert tisize%2==0\n",
        "        tisize = tisize // 2\n",
        "    _ = inputs = Input(shape=(nz,))\n",
        "    _ = Reshape((nz, 1,1))(_)\n",
        "    _ = Conv2DTranspose(filters=cngf, kernel_size=tisize, strides=1, use_bias=False,\n",
        "                           kernel_initializer = conv_init, \n",
        "                           name = 'initial.{0}-{1}.convt'.format(nz, cngf))(_)\n",
        "    _ = BatchNormalization(gamma_initializer = gamma_init, momentum=0.9, axis=1, epsilon=1.01e-5,\n",
        "                               name = 'initial.{0}.batchnorm'.format(cngf))(_, training=1)\n",
        "    _ = Activation(\"relu\", name = 'initial.{0}.relu'.format(cngf))(_)\n",
        "    csize, cndf = tisize, cngf\n",
        "    \n",
        "\n",
        "    while csize < isize//2:\n",
        "        in_feat = cngf\n",
        "        out_feat = cngf//2\n",
        "        _ = Conv2DTranspose(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
        "                        kernel_initializer = conv_init, padding=\"same\",\n",
        "                        name = 'pyramid.{0}-{1}.convt'.format(in_feat, out_feat)             \n",
        "                        ) (_)\n",
        "        _ = BatchNormalization(gamma_initializer = gamma_init, \n",
        "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
        "                                   name = 'pyramid.{0}.batchnorm'.format(out_feat))(_, training=1)\n",
        "        \n",
        "        _ = Activation(\"relu\", name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
        "        csize, cngf = csize*2, cngf//2\n",
        "    _ = Conv2DTranspose(filters=nc, kernel_size=4, strides=2, use_bias=False,\n",
        "                        kernel_initializer = conv_init, padding=\"same\",\n",
        "                        name = 'final.{0}-{1}.convt'.format(cngf, nc)\n",
        "                        )(_)\n",
        "    outputs = Activation(\"tanh\", name = 'final.{0}.tanh'.format(nc))(_)\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQBeIh2bY5yb",
        "colab_type": "text"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK2upJ5xY5ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "n_extra_layers = 0\n",
        "Diters = 5\n",
        "λ = 10\n",
        "\n",
        "imageSize = 32\n",
        "batchSize = 64\n",
        "lrD = 1e-4\n",
        "lrG = 1e-4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYbTJfm-Y5yn",
        "colab_type": "text"
      },
      "source": [
        "print models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSfTYSaGY5yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netD = DCGAN_D(imageSize, nz, nc, ndf, n_extra_layers)\n",
        "netD.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opAyrS2yY5yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netG = DCGAN_G(imageSize, nz, nc, ngf, n_extra_layers)\n",
        "netG.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENxECYB8Y5y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import RMSprop, SGD, Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYBF6jt3Y5zB",
        "colab_type": "text"
      },
      "source": [
        "compute Wasserstein loss and  gradient penalty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j341F66AY5zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netD_real_input = Input(shape=(nc, imageSize, imageSize))\n",
        "noisev = Input(shape=(nz,))\n",
        "netD_fake_input = netG(noisev)\n",
        "\n",
        "ϵ_input = K.placeholder(shape=(None, nc,imageSize,imageSize))\n",
        "netD_mixed_input = Input(shape=(nc, imageSize, imageSize),  tensor=netD_real_input + ϵ_input)\n",
        "\n",
        "\n",
        "loss_real = K.mean(netD(netD_real_input))\n",
        "loss_fake = K.mean(netD(netD_fake_input))\n",
        "\n",
        "grad_mixed = K.gradients(netD(netD_mixed_input), [netD_mixed_input])[0]\n",
        "norm_grad_mixed = K.sqrt(K.sum(K.square(grad_mixed), axis=[1,2,3]))\n",
        "grad_penalty = K.mean(K.square(norm_grad_mixed -1))\n",
        "\n",
        "loss = loss_fake - loss_real + λ * grad_penalty\n",
        "\n",
        "\n",
        "training_updates = Adam(lr=lrD).get_updates(netD.trainable_weights,[],loss)\n",
        "netD_train = K.function([netD_real_input, noisev, ϵ_input],\n",
        "                        [loss_real, loss_fake],    \n",
        "                        training_updates)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1eefes6Y5zS",
        "colab_type": "text"
      },
      "source": [
        "loss for netG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ITg8GpY5zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = -loss_fake \n",
        "training_updates = Adam(lr=lrG).get_updates(netG.trainable_weights,[], loss)\n",
        "netG_train = K.function([noisev], [loss], training_updates)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "NzqYN2o9Y5zf",
        "colab_type": "text"
      },
      "source": [
        "Download CIFAR10 if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KI6vzTrY5zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tarfile\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "import os\n",
        "import urllib\n",
        "from urllib.request import urlretrieve\n",
        "def reporthook(a,b,c):\n",
        "    print(\"\\rdownloading: %5.1f%%\"%(a*b*100.0/c), end=\"\")\n",
        "tar_gz = \"cifar-10-python.tar.gz\"\n",
        "if not os.path.isfile(tar_gz):\n",
        "        print('Downloading data from %s' % url)\n",
        "        urlretrieve(url, tar_gz, reporthook=reporthook)\n",
        "\n",
        "import pickle\n",
        "train_X=[]\n",
        "train_y=[]\n",
        "tar_gz = \"cifar-10-python.tar.gz\"\n",
        "with tarfile.open(tar_gz) as tarf:\n",
        "    for i in range(1, 6):\n",
        "        dataset = \"cifar-10-batches-py/data_batch_%d\"%i\n",
        "        print(\"load\",dataset)\n",
        "        with tarf.extractfile(dataset) as f:\n",
        "            result = pickle.load(f, encoding='latin1')\n",
        "        train_X.extend( result['data'].reshape(-1,3,32,32)/255*2-1)\n",
        "        train_y.extend(result['labels'])\n",
        "    train_X=np.float32(train_X)\n",
        "    train_y=np.int32(train_y)\n",
        "    dataset = \"cifar-10-batches-py/test_batch\"\n",
        "    print(\"load\",dataset)\n",
        "    with tarf.extractfile(dataset) as f:\n",
        "        result = pickle.load(f, encoding='latin1')\n",
        "        test_X=np.float32(result['data'].reshape(-1,3,32,32)/255*2-1)\n",
        "        test_y=np.int32(result['labels'])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE7ODz5bY5zp",
        "colab_type": "text"
      },
      "source": [
        "also using test_X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVV6oIdaY5zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = np.concatenate([train_X, test_X])\n",
        "train_X = np.concatenate([train_X[:,:,:,::-1], train_X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zFXXoRY5zz",
        "colab_type": "text"
      },
      "source": [
        "utility to show images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH7Z0q41Y5z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display\n",
        "def showX(X, rows=1):\n",
        "    assert X.shape[0]%rows == 0\n",
        "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
        "    # N*3072 -> N*3*32*32 -> 32 * 32N * 3\n",
        "    int_X = np.moveaxis(int_X.reshape(-1,3,32,32), 1, 3)\n",
        "    int_X = int_X.reshape(rows, -1, 32, 32,3).swapaxes(1,2).reshape(rows*32,-1, 3)\n",
        "    display(Image.fromarray(int_X))\n",
        "# 訓練資料， X 的前 20 筆\n",
        "showX(train_X[:20])\n",
        "print(train_y[:20])\n",
        "name_array = np.array(\"airplane car bird cat deer dog frog horse boat truck\".split(' '))\n",
        "print(name_array[train_y[:20]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYuV48BHY5z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_noise = np.random.normal(size=(batchSize, nz)).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "TKmySl5HY50E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "niter = 100\n",
        "gen_iterations = 0\n",
        "errG = 0\n",
        "targetD = np.float32([2]*batchSize+[-2]*batchSize)[:, None]\n",
        "targetG = np.ones(batchSize, dtype=np.float32)[:, None]\n",
        "for epoch in range(niter):\n",
        "    i = 0\n",
        "    #  每個 epoch 洗牌一下\n",
        "    np.random.shuffle(train_X)\n",
        "    batches = train_X.shape[0]//batchSize\n",
        "    while i < batches:\n",
        "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
        "            _Diters = 100\n",
        "        else:\n",
        "            _Diters = Diters\n",
        "        j = 0\n",
        "        while j < _Diters and i < batches:\n",
        "            j+=1\n",
        "            real_data = train_X[i*batchSize:(i+1)*batchSize]\n",
        "            i+=1\n",
        "            noise = np.random.normal(size=(batchSize, nz))        \n",
        "            ϵ = real_data.std() * np.random.uniform(-0.5,0.5, size=real_data.shape) \n",
        "            ϵ *= np.random.uniform(size=(batchSize, 1,1,1))\n",
        "            errD_real, errD_fake  = netD_train([real_data, noise, ϵ]) \n",
        "            errD = errD_real - errD_fake\n",
        "       \n",
        "        if gen_iterations%500==0:\n",
        "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
        "            % (epoch, niter, i, batches, gen_iterations,errD, errG, errD_real, errD_fake), time.time()-t0)\n",
        "            fake = netG.predict(fixed_noise)\n",
        "            showX(fake, 4)\n",
        "        \n",
        "        noise = np.random.normal(size=(batchSize, nz))        \n",
        "        errG, = netG_train([noise])\n",
        "        gen_iterations+=1 \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAVN_iV6Y50K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo-8KzKiY50Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}